{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN4yq+uNJne2bCfka6X1MTf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayyucedemirbas/kvasir_seg_self-supervised/blob/main/kvasir_seg_ssl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import EfficientNetB0"
      ],
      "metadata": {
        "id": "ilY5IhI11gw2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://datasets.simula.no/downloads/kvasir-seg.zip\n",
        "!unzip -qq kvasir-seg.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRCTwF0z2ZLV",
        "outputId": "cf429444-c813-426e-be52-986d6aca9a5e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-10 23:14:01--  https://datasets.simula.no/downloads/kvasir-seg.zip\n",
            "Resolving datasets.simula.no (datasets.simula.no)... 128.39.36.14\n",
            "Connecting to datasets.simula.no (datasets.simula.no)|128.39.36.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46227172 (44M) [application/zip]\n",
            "Saving to: ‘kvasir-seg.zip’\n",
            "\n",
            "kvasir-seg.zip      100%[===================>]  44.08M  14.1MB/s    in 3.1s    \n",
            "\n",
            "2024-12-10 23:14:04 (14.1 MB/s) - ‘kvasir-seg.zip’ saved [46227172/46227172]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "plnh9AvH1aqV"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image_path):\n",
        "    \"\"\"Preprocess the input image.\"\"\"\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    return image\n",
        "\n",
        "def data_augment(image):\n",
        "    \"\"\"Apply augmentations for contrastive learning.\"\"\"\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
        "    image = tf.image.random_crop(image, size=(200, 200, 3))\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    return image\n",
        "\n",
        "def contrastive_data_loader(image_paths, batch_size):\n",
        "    \"\"\"Load and prepare contrastive data.\"\"\"\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
        "    dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.map(lambda x: (data_augment(x), data_augment(x)),\n",
        "                          num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.shuffle(1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/Kvasir-SEG\"\n",
        "\n",
        "image_paths = tf.io.gfile.glob(os.path.join(DATASET_PATH, \"images\", \"*.*\"))\n",
        "random.shuffle(image_paths)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = contrastive_data_loader(image_paths, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Define the SimCLR model backbone\n",
        "def create_simclr_model():\n",
        "    \"\"\"Create a SimCLR-style model.\"\"\"\n",
        "    base_model = EfficientNetB0(include_top=False, weights=None, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = True\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "    features = base_model(inputs, training=True)\n",
        "    pooled_features = GlobalAveragePooling2D()(features)\n",
        "    projection_head = Dense(128, activation=\"relu\")(pooled_features)\n",
        "    projection_head = Dense(128)(projection_head)\n",
        "\n",
        "    model = tf.keras.Model(inputs, projection_head)\n",
        "    return model\n",
        "\n",
        "simclr_model = create_simclr_model()\n",
        "\n"
      ],
      "metadata": {
        "id": "61UuUF5t1rHg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity = keras.losses.CosineSimilarity(axis=-1, reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "\n",
        "def nt_xent_loss(features):\n",
        "    \"\"\"Normalized Temperature-scaled Cross Entropy Loss.\"\"\"\n",
        "    batch_size = tf.shape(features)[0] // 2\n",
        "\n",
        "    labels = tf.eye(batch_size * 2)\n",
        "    masks = tf.eye(batch_size * 2)\n",
        "\n",
        "    similarities = tf.linalg.matmul(features, features, transpose_b=True) / 0.5\n",
        "    similarities -= masks * 1e9\n",
        "\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels, similarities))\n",
        "    return loss\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n"
      ],
      "metadata": {
        "id": "NgSHvnju1upB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_loss = 0.0\n",
        "    for step, (img_1, img_2) in enumerate(train_dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            features_1 = simclr_model(img_1, training=True)\n",
        "            features_2 = simclr_model(img_2, training=True)\n",
        "\n",
        "            features = tf.concat([features_1, features_2], axis=0)\n",
        "            loss = nt_xent_loss(features)\n",
        "\n",
        "        gradients = tape.gradient(loss, simclr_model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, simclr_model.trainable_variables))\n",
        "\n",
        "        epoch_loss += loss\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {epoch_loss / (step + 1):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPXZ9bqz1xeH",
        "outputId": "03c98276-eab8-4afd-f1e4-fe7a39700158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 999999616.0000\n",
            "Epoch 2/100, Loss: 999999104.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simclr_model.save(\"simclr_kvasir_pretrained_model\")"
      ],
      "metadata": {
        "id": "bcM2sO6i1yz8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}